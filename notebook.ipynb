{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"StudentPerformanceFactors.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "display(df.sample(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "display(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values per Column:\\n\", missing_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values by replacing them with column means\n",
    "for column in df.columns:\n",
    "    if df[column].dtype != 'object':\n",
    "        df[column].fillna(df[column].mean(), inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data into numerical if necessary\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "display(df.sample(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "## Distribution of numerical features\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, col in enumerate(numeric_columns, 1):\n",
    "    if i > 6:\n",
    "        break  # Limiting the number of plots to avoid overcrowding\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Relationship between study hours and exam scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=df[\"Hours_Studied\"], y=df[\"Exam_Score\"], alpha=0.7)\n",
    "plt.title(\"Relationship Between Study Hours and Exam Scores\")\n",
    "plt.xlabel(\"Study Hours\")\n",
    "plt.ylabel(\"Exam Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation analysis\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Heatmap of Correlations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Most influential factors for exam performance\n",
    "correlations = df.corr()['Exam_Score'].sort_values(ascending=False)\n",
    "print(\"Most influential factors:\\n\", correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features (X) and target variable (y)\n",
    "y = df['Exam_Score']\n",
    "X = df.drop(columns=['Exam_Score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "## Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional Models\n",
    "models = {\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'XGBoost': XGBRegressor()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    results[name] = mse\n",
    "    print(f\"{name} MSE: {mse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "## Linear Regression\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "print(f'Linear Regression MAE: {mae_lr}')\n",
    "print(f'Linear Regression MSE: {mse_lr}')\n",
    "print(f'Linear Regression RMSE: {rmse_lr}')\n",
    "print(f'Linear Regression R2 Score: {r2_lr}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f'Random Forest MAE: {mae_rf}')\n",
    "print(f'Random Forest MSE: {mse_rf}')\n",
    "print(f'Random Forest RMSE: {rmse_rf}')\n",
    "print(f'Random Forest R2 Score: {r2_rf}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Distribution\n",
    "errors = y_test - rf_model.predict(X_test)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(errors, bins=30, kde=True)\n",
    "plt.title(\"Error Distribution\")\n",
    "plt.xlabel(\"Prediction Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing model performance\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=y_test, y=y_pred_rf)\n",
    "plt.xlabel('Actual Exam Scores')\n",
    "plt.ylabel('Predicted Exam Scores')\n",
    "plt.title('Random Forest: Actual vs Predicted Exam Scores')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.regplot(x=y_test, y=y_pred_lr, scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
    "plt.xlabel('Actual Exam Scores')\n",
    "plt.ylabel('Predicted Exam Scores')\n",
    "plt.title('Linear Regression: Actual vs Predicted Exam Scores')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
